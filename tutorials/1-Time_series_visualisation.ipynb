{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series analysis and visualisation\n",
    "\n",
    "Water resource infrastructure (and drainage infrastructure) deals with water inflows and uses that vary over time. To design infrastructure and / or adaptation measures, a first step is to use time series to assess the variations of key water variables over time: this is necessary to assess their performance.\n",
    "\n",
    "In this tutorial we have a first look at the data from the Conowingo case-study:\n",
    "\n",
    "**Part 1:** We unpack the monthly demand data and use that as an introduction to the Pandas library. This is Excel in Python!\n",
    "\n",
    "**Part 2:** We visualise the variable inflows to the Conowingo reservoir and contrast this with demand.\n",
    "\n",
    "**Part 3:** An exercise to explore the results from Part 2 using Gemini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Analysis using Pandas\n",
    "\n",
    "In this part we will look at the demand data from Conowingo. These demands are also listed on the reservoir's schematic.\n",
    "\n",
    "First, we need to import any library we want to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Pandas?\n",
    ">* Pandas is an **extremely popular library** for data analysis. You can generally think of it as an **Excel replacement**.\n",
    ">* Like Excel, it reads tabular data and provides a **full toolbox** to manipulate and analyse it.\n",
    ">* It is able to **read data from most common file types**: Excel, CXV, Text, etc.\n",
    ">* Even better, **it can write tables back into these formats**.\n",
    ">* It is practical for **time series analysis**, as it provides hands-on tools for dealing with dates/time and missing data\n",
    "\n",
    "### Why use Pandas?\n",
    ">* As **datasets are becoming bigger and more complex**, tools such as pandas are becoming increasingly essential.\n",
    ">* Anlysis using Python and Pandas is generally **more transparent and easier to follow** than that done in speadsheets.\n",
    ">* Contrary to Excel, it makes it easy to **separate input data and analysis results** into separate spreadsheets. This way the original data is kept.\n",
    ">* When working with multiple datasets, pandas **code can be reapplied easily**.\n",
    "\n",
    "### Do I need to be a Python wizard?\n",
    ">* No! In general **AI tools (Gemini, ChatGPT, etc.) can help you**. They are pretty good with queries such as \"I want to do this and that with pandas in Python\" (or any other library).\n",
    ">* You do **need to double-check** that the AI tool is doing what you want though!\n",
    ">* If the AI tool gives you an imcomplete and / or difficult to use answer: (i) **use AI prompts to refine the answer**, and (ii) **use the documentation**, in general extensive and easy-to-search for popular Python libraries (e.g., for Pandas: https://pandas.pydata.org/docs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creating a DataFrame from spreadsheet data\n",
    ">* Pandas allows reading importing data from an Excel/csv file into a pandas DataFrame.\n",
    ">* We can read a CSV file with pandas by using `pd.read_csv`. Excel files can be read using `pd.read_excel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"data\\Conowingo_data.xlsx\" # r is to treat all characters between the quotes as a raw string.\n",
    "                                  # Otherwise, special couples, such as \"\\n\", may be treated as a new line\n",
    "\n",
    "# Read specific extent (columns and rows) from a specific worksheet\n",
    "demand_df = pd.read_excel(filepath, \n",
    "                          sheet_name='Demands', # Specify the worksheet\n",
    "                          usecols=\"A:E\",        # Specify columns (e.g., columns A to E)\n",
    "                          skiprows=0,           # (Optional) Skip the first n row if necessary (skiprows=0 does not skip a row)\n",
    "                          nrows=12,             # (Optional) Read the first 12 rows after the first row (first row will be column titles)\n",
    "                          index_col=0)          # Dataframe index column (0 indicates the first column)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Selecting and displaying parts of a DataFrame\n",
    "\n",
    "Here we are going to look at:\n",
    ">* Displaying the index of the DataFrame, i.e. the row labels.\n",
    ">* Displaying the columns of the DataFrame, i.e., the... column labels.\n",
    ">* Displaying the first / last n rows of a DataFrame: the `head` and `tail` methods.\n",
    ">* Selecting slices of the DataFrame: a column, a row, one value, a range of values. Pay close attention to methods `loc` and `iloc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the index of a DataFramme\n",
    ">* `DataFrame.index` will return information about the row names. In timeseries the index is generally a list of temporal markers. Here, months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demand_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the columns of a DataFramme\n",
    ">* `DataFrame.columns` will return information about the columns names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demand_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the first / last few rows of a DataFrame\n",
    ">* `DataFrame.head(n)` will return the first n rows of the DataFrame.\n",
    ">* `DataFrame.tail(n)` will return the last n rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only the first 3 rows of the DataFrame\n",
    "demand_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only the last 2 rows of the dataframe\n",
    "demand_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting values: slicing a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Referencing one column by using `DataFrame[name_of_column]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df[\"Minimum environmental flows (cfs)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Subsetting a DataFrame by using `DataFrame.loc`. This selection finds a value within the DataFrame below `df.loc[index, column]` where index and column are their **labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.loc[\"June\", \"Minimum environmental flows (cfs)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Use the notation `:` when you want to select all the values for either rows or columns\n",
    "\n",
    "We get the same result as with calling a column above, but we can also use this to display a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.loc[:, \"Minimum environmental flows (cfs)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.loc[\"June\", :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Subsetting a DataFrame by using `DataFrame.iloc`. This selection finds a values as above but now index and column are instead their **positions**. Please note: In python, position indexing starts from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.iloc[6, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Subsetting a DataFrame with a range of criteria. Can be done both with `df.loc` and `df.iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.loc[[\"November\", \"March\", \"August\", \"May\"], [\"Peach Bottom Nuclear Power Plant (cfs)\",\"Chester city (cfs)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.iloc[2:5, 1:3] # Display the slice of the dataframe from 3rd to 5th row and 2nd to 3rd column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Manipulating a DataFrame\n",
    "\n",
    "This presentes some useful operations:\n",
    ">* Conversion from one set of units to another. **Unit conversion is very important for calculations**, as data sources using different units need to be put together in a single coherent system.\n",
    ">* Adding columns.\n",
    ">* Summing up data with `df.sum()`.\n",
    ">* Averaging data with `df.mean()`.\n",
    ">* Removing columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit conversion\n",
    "\n",
    "Our data has an annoying format: cubic feet per second. Let's convert to metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in the dataframe to metric system units: conversion from cfs to m3/s\n",
    "demand_df = demand_df * 0.3048**3\n",
    "\n",
    "# We need to also change \"cfs\" with \"m3/s\" in column headers\n",
    "demand_df.columns = pd.Series(demand_df.columns).replace('cfs', 'm3/s', regex=True)\n",
    "\n",
    "# What does that look like, rounded to the first decimal place?\n",
    "demand_df.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting totals\n",
    "\n",
    ">* Example uses of `df_sum`, note the axis.\n",
    "\n",
    "Here we calculate the total of demands, and add it as a new column to our data frame. Then we do the same for potable demand only (Chester & Baltimore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of values across each row in the dataframe (for total monthly demand)\n",
    "# Calculated sum will be added as a new column to the copied dataframe\n",
    "demand_df[\"Total Demand (m3/s)\"]  = demand_df.sum(axis=1)\n",
    "demand_df.round(1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for potable demand\n",
    "demand_df[\"Total Potable Water Demand (m3/s)\"]  = demand_df[\"Chester city (m3/s)\"] + demand_df[\"Baltimore city (m3/s)\"]\n",
    "demand_df.round(1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting averages\n",
    "\n",
    ">* Example uses of `df_mean`, note the axis.\n",
    "\n",
    "We deduce how much each water use contributes to total demand over the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average volumetric demand across each column, throughout the year\n",
    "annual_means = demand_df.mean(axis=0)\n",
    "\n",
    "# Print the result\n",
    "print(annual_means.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_means[\"Total Demand (m3/s)\"].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percent contribution for each demand to the annual total demand\n",
    "percent_contribution = (annual_means.iloc[:4] / annual_means[\"Total Demand (m3/s)\"]) * 100\n",
    "\n",
    "# Print the result\n",
    "print(percent_contribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set axis=1 overwise drop will try to remove a row as the default is axis=0\n",
    "demand_df = demand_df.drop(\"Total Potable Water Demand (m3/s)\", axis=1)\n",
    "demand_df.round(1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* **Question 1. How do you use `loc` and `iloc` methods to display only Chester and Baltimore demands for the summer months?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to answer here and / or look up the answers in the Tutorial 1 doc.\n",
    "# With loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With iloc (note the results should be the same!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* **Question 2. What is the summer total demand, in millions cubic meters (hm3), for each of the two cities?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to answer here and / or look up the answers in the Tutorial 1 doc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Visualising time series data\n",
    "\n",
    "Now we look at inflows to Conowingo reservoir over a 70-year period, from 1932 to 2001 included.\n",
    "\n",
    "### Working with timeseries data\n",
    ">* We often work with data with a temporal axis, pandas makes it easy to deal with this.\n",
    ">* We normally set the time-axis as the index.\n",
    ">* Control for reading in datasets, skip rows and columns.\n",
    "\n",
    "## 2.1 First plots directly using pandas\n",
    "\n",
    "First we load the inflows and plot them. Then we consolidate into a single time series and we convert to metric units. \n",
    "\n",
    "### We can set date to be the index column and recognise this as a DateTimeIndex\n",
    ">* Use `index_col` to set the column you want.\n",
    ">* Use `parse_date` so dates are automatically read in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read specific extent (columns and rows) from a specific worksheet\n",
    "flow_df = pd.read_excel(filepath, \n",
    "                        sheet_name='Flow data', # Specify the worksheet\n",
    "                        index_col=0,  # Dataframe index column (0 indicates the 1st column)\n",
    "                        parse_dates=True)  # The index is interpreted as a date by pandas          \n",
    "\n",
    "flow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "flow_df.loc[:,[\"Susquehanna River Inflow (cfs)\",\"Lateral Inflow (cfs)\"]].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly river inflows to the reservoirs are the bulk of the total inflows. Let's have a new, total inflow column using SI units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df['Total inflows (m3/s)'] = flow_df.sum(axis=1) * 0.3048**3\n",
    "\n",
    "flow_df.loc[:, ['Total inflows (m3/s)']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only a subset in the dataframe\n",
    "flow_df.loc[\"1991-3-1\":\"1991-5-31\",['Total inflows (m3/s)']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* **Question 3. Pandas plots are very easy to draw but what separates them from plots for a report?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Using the plots provided in `model` folder.\n",
    "\n",
    "The `model` folder contains ready-made code that will be used in the tutorials... and that you can use in the coursework. In this way, the coding required in the coursework will be minimal if you can astutely re-use the code provided.\n",
    "\n",
    "But we need to **import** that code to use it. In the coming weeks we'll do that at the top of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also good to **look up the method we are calling, and the text right below the first line**, to understand what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visuals.flow_timeseries(time_series=flow_df['Total inflows (m3/s)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how this is similar to the time series plot above, but this time everything is specified. We can also plot the time series between specified dates, for instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This library enables us to define dates.\n",
    "import datetime\n",
    "\n",
    "fig = visuals.flow_timeseries(time_series=flow_df['Total inflows (m3/s)'],\n",
    "                              first_date=datetime.date(1964, 1, 1),\n",
    "                              last_date=datetime.date(1964,12,31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4. What do we notice when we compare and contrast the plot of inflows over the whole period vs. the 1964 inflows?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Investigating year-to-year variability.\n",
    "\n",
    ">* Pandas provides an easy way to do totals or averages over a month / year, with `df.resample.sum` or `df.resample.mean`.\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the dataframe into annual average flows\n",
    "flow_df['Total inflows (m3/s)'].resample(\"YE\").mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is signifiant year-to-year variability!\n",
    "And, if we want annual total inflows in km$^3$ (billion cubic meters), we can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual total inflows in m3\n",
    "annual_totals = flow_df['Total inflows (m3/s)'].resample(\"YE\").sum() * 86400  # Converting to m3/day and summing the daily totals\n",
    "\n",
    "# Conversion to km3\n",
    "annual_totals = annual_totals / 1E9\n",
    "\n",
    "# Average annual flow\n",
    "print('Average annual flow in km3 is:')\n",
    "print(annual_totals.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Investigating within-year and year-to-year variability.\n",
    "\n",
    ">* The `visuals.py` document included within the `model` folder includes methods to visualise the annual cycle of inflows, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visuals.monthly_averages(flow_df['Total inflows (m3/s)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* We can also plot the monthly average flows for each of the 70 years, and superimpose this to the demand.\n",
    ">* Note how we called another library, numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visuals.monthly_averages(flow_df['Total inflows (m3/s)'], plot_all_years=True)\n",
    "import numpy as np\n",
    "fig.axes[0].plot(np.arange(1,13,1), demand_df['Total Demand (m3/s)'], c='r', label='Total demand')\n",
    "fig.axes[0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In particular, is 1964 that dry?\n",
    "fig = visuals.monthly_averages(flow_df['Total inflows (m3/s)'][flow_df.index.year==1964])\n",
    "fig.axes[0].plot(np.arange(1,13,1), demand_df['Total Demand (m3/s)'], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* **Question 5. What did the visualisations tell us about the variability at our reservoir site?**\n",
    ">* **Question 6. What does that tell us about the necessity of a reservoir?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Using Gemini to help with Python.\n",
    "\n",
    ">* **Question 7. How can we know the number of days where inflows are smaller than the total demands over the 70 years?**\n",
    "\n",
    "Use Gemini, and start with the following prompt: `I have a daily time series as a Series object from the Python library pandas. I would like to know for how many days in August the values are below 100. How do I do this?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to work out toward a solution in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The right answer will be 1,254 days, including 420 in August, 424 in September, 204 in July and 160 in October."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mac441",
   "language": "python",
   "name": "mac441"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
